{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMwnkJ/4NCvRGzntpVBVwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/07_document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_0ZZ8bo1mgH"
      },
      "source": [
        "# 07 単語埋め込みを使った文書分類\n",
        "* 今回は、fastTextのような学習済みの単語埋め込みは使わない。\n",
        "* 単語埋め込み自体の学習も、ネットワークの学習と同時におこなう。\n",
        "* IMDbデータの準備も、`torch.torchtext`を使っておこなう。\n",
        " * つまりすべてをPyTorchのなかでおこなう。\n",
        "* 参考資料\n",
        " * https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyjU004LNbMt"
      },
      "source": [
        "## データをどう扱うか\n",
        "* ネットワークへの入力は、単語埋め込みを、単語の出現順どおりに並べた列にする。\n",
        " * ミニバッチは[ミニバッチのなかでの最大文書長, ミニバッチのサイズ, 単語埋め込み次元数]という形の3階のテンソルになる。\n",
        "* そして、前向き計算のなかではじめて、単語埋め込みの平均をとることにする。\n",
        " * `.mean(0)`と、軸0で平均をとることになる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_puYg6Zi8x3"
      },
      "source": [
        "## 07-00 Google Colabのランタイムのタイプを変更する\n",
        "* Google ColabのランタイムのタイプをGPUに変更しておこう。\n",
        " * 上のメニューの「ランタイム」→「ランタイムのタイプを変更」→「ハードウェア　アクセラレータ」から「GPU」を選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLEeO0fw23Xp"
      },
      "source": [
        "## 07-01 torchtextを使ってIMDbデータを読み込む\n",
        "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
        " * https://torchtext.readthedocs.io/en/latest/datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7epLZe3JmF"
      },
      "source": [
        "### 実験の再現性確保のための設定など\n",
        "* torch.backends.cudnn.deterministicをTrueにするのは、こうしないと、GPU上での計算が毎回同じ値を与えないため。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nSqNzof1lTJ"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, LabelField, BucketIterator\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y1_GyXg22f6"
      },
      "source": [
        "### torchtextのフィールド\n",
        "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
        " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
        "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
        " * tokenizerは、デフォルトでは単にstring型のsplitメソッドを適用するだけになる。これは高速だが、tokenizationとしては雑。\n",
        "* LABELフィールドは、ラベルの前処理に使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjq8oooE2uQY"
      },
      "source": [
        "TEXT = Field(tokenize=\"spacy\")\n",
        "LABEL = LabelField()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEq23GS3Vxl"
      },
      "source": [
        "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
        "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
        "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。\n",
        " * string型のsplitメソッドでtokenizeすると、時間はあまりかからない。（そのかわり、やや雑なtokenizationになる。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzgVXf3G3YPI"
      },
      "source": [
        "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0sltPjT3j36"
      },
      "source": [
        "### 最初の文書を見てみる\n",
        "（ちなみに、`vars`関数は、モジュール、クラス、インスタンス、あるいはそれ以外の`__dict__`属性を持つオブジェクトの、`__dict__`属性を辞書として返す組み込み関数。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692vrq6B3gZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "906c85f6-f542-4e8a-e420-09a4c9f79632"
      },
      "source": [
        "print(vars(train_valid_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['McConaughey', 'in', 'a', 'horror', '/', 'thriller', '?', 'I', 'had', 'to', 'see', 'this', '.', 'I', 'was', 'pleasantly', 'surprised.<br', '/><br', '/>The', 'plot', 'is', 'told', 'in', 'flashback', 'mode', ',', 'and', 'it', 'concerns', 'an', 'otherwise', 'normal', 'and', 'happy', 'family', 'of', 'three', 'going', 'through', 'a', 'very', 'bizarre', 'predicament', '.', 'I', 'ca', \"n't\", 'say', 'much', 'more', 'without', 'spoiling', 'the', 'whole', 'movie', ',', 'sorry', '.', 'Just', 'know', 'that', 'if', 'you', 'decide', 'to', 'watch', 'it', ',', 'you', \"'ll\", 'be', ',', 'in', 'the', 'very', 'least', ',', 'surprised.<br', '/><br', '/>All', 'the', 'main', 'players', 'are', 'very', 'good', '.', 'Bill', 'Paxton', 'did', 'a', 'great', 'job', 'directing', 'those', 'kids', ',', 'and', 'his', 'acting', 'is', 'awesome', '.', 'McConaughey', \"'s\", 'acting', 'is', 'solid', 'throughout', 'and', 'fits', 'the', 'bill', 'perfectly.<br', '/><br', '/>This', 'movie', 'challenges', 'you', 'to', 'think', '.', 'Is', 'Dad', 'crazy', '?', 'Is', 'there', 'a', 'God', '?', 'Do', 'Demons', 'exist', '?', 'How', 'far', 'would', 'you', 'go', 'to', 'right', 'a', 'wrong', '.', 'And', 'what', 'is', '\"', 'right', '\"', 'anyway', '?', 'I', \"'m\", 'still', 'thinking.<br', '/><br', '/>And', 'thus', 'I', 'recommend', '\"', 'Frailty', '\"', '.', '7/10', 'and', 'this', 'is', 'one', 'of', 'those', 'movies', 'that', 'deserves', 'and', 'rewards', 'a', 'second', ',', 'or', 'even', 'third', 'viewing', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrXwYMVH3orf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e251d43f-05c1-4be9-d583-1af10fde35eb"
      },
      "source": [
        "print(train_valid_data.examples[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['McConaughey', 'in', 'a', 'horror', '/', 'thriller', '?', 'I', 'had', 'to', 'see', 'this', '.', 'I', 'was', 'pleasantly', 'surprised.<br', '/><br', '/>The', 'plot', 'is', 'told', 'in', 'flashback', 'mode', ',', 'and', 'it', 'concerns', 'an', 'otherwise', 'normal', 'and', 'happy', 'family', 'of', 'three', 'going', 'through', 'a', 'very', 'bizarre', 'predicament', '.', 'I', 'ca', \"n't\", 'say', 'much', 'more', 'without', 'spoiling', 'the', 'whole', 'movie', ',', 'sorry', '.', 'Just', 'know', 'that', 'if', 'you', 'decide', 'to', 'watch', 'it', ',', 'you', \"'ll\", 'be', ',', 'in', 'the', 'very', 'least', ',', 'surprised.<br', '/><br', '/>All', 'the', 'main', 'players', 'are', 'very', 'good', '.', 'Bill', 'Paxton', 'did', 'a', 'great', 'job', 'directing', 'those', 'kids', ',', 'and', 'his', 'acting', 'is', 'awesome', '.', 'McConaughey', \"'s\", 'acting', 'is', 'solid', 'throughout', 'and', 'fits', 'the', 'bill', 'perfectly.<br', '/><br', '/>This', 'movie', 'challenges', 'you', 'to', 'think', '.', 'Is', 'Dad', 'crazy', '?', 'Is', 'there', 'a', 'God', '?', 'Do', 'Demons', 'exist', '?', 'How', 'far', 'would', 'you', 'go', 'to', 'right', 'a', 'wrong', '.', 'And', 'what', 'is', '\"', 'right', '\"', 'anyway', '?', 'I', \"'m\", 'still', 'thinking.<br', '/><br', '/>And', 'thus', 'I', 'recommend', '\"', 'Frailty', '\"', '.', '7/10', 'and', 'this', 'is', 'one', 'of', 'those', 'movies', 'that', 'deserves', 'and', 'rewards', 'a', 'second', ',', 'or', 'even', 'third', 'viewing', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMuAOum3rB5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af7395b8-ac81-4cf9-9f4e-ced1d77e8be7"
      },
      "source": [
        "print(train_valid_data.examples[0].label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgZgQbyD3u9D"
      },
      "source": [
        "### テストセット以外の部分を訓練データと検証データに分ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2FtnEKZ32hM"
      },
      "source": [
        "train_data, valid_data = train_valid_data.split(split_ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fzsi9ZC36eR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2e2b8cfc-2968-4853-ccc0-921e3cbd02ee"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oXz2lvB37Vm"
      },
      "source": [
        "### データセットの語彙とラベルを作る\n",
        "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBQeD7yC37x4"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iv6RSh3HmLf"
      },
      "source": [
        "なぜ語彙サイズが25,000ではなく25,002なのかについては、少し下の説明を参照。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWuYQthC4Ml8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "98064e2e-dbe0-45f5-a082-ba35709586d0"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW4eR-K44Rba"
      },
      "source": [
        "### 出現頻度順で上位２０単語を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jan98ffr4PXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eac3c30f-ae48-4cf2-dca4-59ce5eb42f4f"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232103), (',', 220515), ('.', 189706), ('and', 125577), ('a', 125352), ('of', 115040), ('to', 107448), ('is', 86946), ('in', 70203), ('I', 62211), ('it', 61179), ('that', 56449), ('\"', 50102), (\"'s\", 49672), ('this', 48320), ('-', 42239), ('/><br', 40900), ('was', 40224), ('as', 34945), ('with', 34442)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKQojOuv4Z38"
      },
      "source": [
        "### 単語ID順に最初の１０単語を見てみる\n",
        "* IDのうち、0と1は、未知語とパディング用の単語という特殊な単語に割り振られている。\n",
        " * 未知語は`<unk>`という特殊な単語に置き換えられる。これのIDが0。\n",
        " * パディングとは、長さが不揃いの複数の文書を同じミニバッチにまとめるとき、すべての文書の長さを無理やりそろえるため、文書末尾に特殊な単語（元々の語彙にない、人工的に用意した単語）を追加すること。\n",
        " * パディング用の単語が`<pad>`になっているのは、上のほうで使ったFieldクラスのインスタンスを作るときのデフォルトの値がこの`<pad>`になっているため。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhXRT3g4Xad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fd0976c-ba6b-46fb-94af-7c0608553b04"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vJfHTdR4qd4"
      },
      "source": [
        "### ラベルのほうのIDを確認する\n",
        "* こちらはnegとposに対応する２つのIDしかない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI7Pz_6R4bYM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb89b1cf-6d91-4b7e-9334-aa00266c4cec"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fccad032ea0>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14_znTjp4w5s"
      },
      "source": [
        "### ミニバッチを取り出すためのiteratorを作る\n",
        "* ミニバッチのサイズを指定する。\n",
        " * ミニバッチのサイズは、性能を出すためにチューニングすべきハイパーパラメータのひとつ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUED86Jb4tUy"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAW9Ec5q6BQO"
      },
      "source": [
        "### 試しに検証セットのiteratorを回してミニバッチをすべて取得して個数を数えてみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpn4tfWl42kY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2aa3f1e8-73d8-46cb-fe90-2c9da9e0c3c4"
      },
      "source": [
        "i = 0\n",
        "for batch in valid_iterator:\n",
        "  i += 1\n",
        "  continue\n",
        "print(f'We have {i} mini-batches in validation set.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 50 mini-batches in validation set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHytOsiSUdeS"
      },
      "source": [
        "### ミニバッチの中身を見てみる\n",
        "* 上記のループを抜けたあとには、変数batchには検証セットの最後のミニバッチが代入されている。\n",
        "* そこで、この最後のミニバッチのshapeを確認する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWW1np1P6OQg"
      },
      "source": [
        "### ミニバッチの形を確認する\n",
        "* ミニバッチの形は、[ミニバッチに含まれる最長文書の文書長, ミニバッチのサイズ]になっていることに注意！\n",
        " * ミニバッチのサイズが最初に来ているのではない！\n",
        "* [ミニバッチのサイズ, ミニバッチに含まれる最長文書の文書長]という形にしたいときは、テキストのfieldを作るときにに以下のようにする。\n",
        "\n",
        "__`TEXT = data.Field(tokenize=\"spacy\", batch_first=True)`__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d78vJW616H7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9790b80-3e55-4927-ebe3-a1ffc817ddc2"
      },
      "source": [
        "batch.text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1989, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHMHkR73VuCD"
      },
      "source": [
        "このミニバッチに含まれる文書のうち、最初のものの単語ID列と、先頭100個のIDを単語に戻したものを表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tZLm0hQVjZE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b4ccb204-f404-4025-a14e-7d058e29f32a"
      },
      "source": [
        "print(batch.text[:, 0])\n",
        "print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:100, 0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1075,  223,   31,  ...,  857,   24,    4], device='cuda:0')\n",
            "By now you 've probably heard a bit about the new Disney dub of Miyazaki 's classic film , Laputa : Castle In The Sky . During late summer of 1998 , Disney released \" Kiki 's <unk> Service \" on video which included a preview of the Laputa dub saying it was due out in \" 1999 \" . It 's obviously way past that year now , but the dub has been finally completed . And it 's not \" Laputa : Castle In The Sky \" , just \" Castle In The Sky \" for the dub\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtDXRKPMT9KW"
      },
      "source": [
        "最後の文書の末尾は「1」で埋められていることが分かる。\n",
        "\n",
        "この1は、パディング用単語のIDだったことを想起されたい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcdyIhK0TUac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2295ed2-e5b0-47c7-fa84-f662af5a6dd6"
      },
      "source": [
        "print(batch.text[:, BATCH_SIZE-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  25, 8329,  928,  ...,    1,    1,    1], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDzk2ghCUD8N"
      },
      "source": [
        "ミニバッチに含まれる文書の長さを調べると、文書が文書長の降順に並べられていることが分かる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PutP_EU4Tca-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5eeb13cf-53d3-4ebb-ee2e-a9ee9e84418b"
      },
      "source": [
        "(batch.text != 1).sum(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1989, 1446, 1411, 1387, 1332, 1246, 1206, 1193, 1191, 1191, 1183, 1181,\n",
              "        1177, 1175, 1163, 1162, 1161, 1155, 1155, 1155, 1150, 1146, 1145, 1143,\n",
              "        1139, 1136, 1126, 1125, 1123, 1122, 1122, 1122, 1122, 1120, 1113, 1111,\n",
              "        1103, 1100, 1095, 1089, 1089, 1083, 1080, 1079, 1077, 1070, 1070, 1065,\n",
              "        1064, 1052, 1051, 1047, 1045, 1041, 1041, 1035, 1035, 1035, 1032, 1032,\n",
              "        1025, 1017, 1016, 1016, 1012, 1004, 1002, 1000,  991,  988,  979,  976,\n",
              "         975,  971,  968,  965,  964,  964,  963,  958,  954,  952,  950,  950,\n",
              "         949,  949,  947,  941,  940,  933,  929,  929,  927,  926,  925,  924,\n",
              "         921,  920,  915,  906], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDZlF0O6doP"
      },
      "source": [
        "## 07-02 MLPによる文書分類の準備\n",
        "* 今回は、ごく簡単なMLPで文書分類をする。\n",
        "* 文書中の全単語トークンの埋め込みベクトルの平均を、MLPの入力とする。\n",
        " * 当然、語順の情報は使われない。\n",
        " * つまり、bag-of-wordsモデルになっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjpel2i46gbD"
      },
      "source": [
        "### 定数の設定\n",
        "* 単語埋め込みベクトルの次元数は128にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPXVLC66NUM"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "NUM_CLASS = len(LABEL.vocab)\n",
        "EMBED_DIM = 128\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsuHjuNp6tvt"
      },
      "source": [
        "### モデルを定義する前にPyTorchの単語埋め込みがどんなものかを見てみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3J7TzxFVMsR"
      },
      "source": [
        "以下のように、語彙サイズと埋め込みの次元数を指定しつつ、torch.nn.Embeddingのインスタンスを作ればよい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP7jJVYT6tBg"
      },
      "source": [
        "embed = nn.Embedding(INPUT_DIM, EMBED_DIM, padding_idx=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUl6lR8JVWTu"
      },
      "source": [
        "パディング用の単語の埋め込みはゼロベクトルになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ZCr9Ll61m8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23b95a40-34b2-4d91-81c7-8f5b6b3b258a"
      },
      "source": [
        "print(embed(torch.tensor([[2,3],[0,1]])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.3862e-01,  1.4106e-01, -1.3354e+00, -2.9340e+00,  1.1411e-01,\n",
            "          -1.2072e+00, -3.0083e-01,  1.4274e-01, -1.3027e+00, -4.9187e-01,\n",
            "          -2.1429e+00,  9.4881e-01, -5.6842e-01, -6.4643e-02,  6.6467e-01,\n",
            "          -2.7836e+00,  1.1366e+00,  9.0886e-01,  9.4943e-01,  2.6565e-02,\n",
            "          -9.2207e-01,  7.0338e-01, -3.6590e-01, -1.9654e-01, -9.2071e-01,\n",
            "           3.1535e-01, -2.1734e-02,  3.4414e-01,  2.2710e-01, -4.5969e-01,\n",
            "          -6.1831e-01,  2.4612e-01, -4.0549e-01, -8.3681e-01,  1.2277e+00,\n",
            "          -4.2971e-01, -2.2121e+00, -3.7802e-01,  9.8382e-01, -1.0895e+00,\n",
            "           2.0171e-01,  2.2145e-02, -1.7753e+00, -7.4896e-01,  2.7808e-01,\n",
            "          -9.6208e-01, -4.2228e-01, -1.1036e+00,  2.4727e-01,  1.4549e+00,\n",
            "          -2.8351e-01, -3.7675e-01, -3.0577e-02, -8.9448e-02, -1.9652e-01,\n",
            "          -9.7133e-01,  9.0046e-01, -2.5233e-01,  1.0669e+00, -2.9846e-01,\n",
            "           8.5576e-01,  1.6098e+00, -1.1893e+00,  1.1677e+00,  3.2765e-01,\n",
            "          -8.3307e-01, -1.6179e+00,  2.2651e-01, -4.3815e-01,  3.2652e-01,\n",
            "          -1.5786e+00, -1.3995e+00,  5.4460e-01, -8.3004e-02, -1.1753e+00,\n",
            "           1.7825e+00,  1.7524e+00, -2.1347e-01,  4.0949e-01,  4.6454e-02,\n",
            "           6.3669e-01, -1.9433e-01, -8.6139e-01,  5.3384e-01,  9.3758e-01,\n",
            "          -9.2248e-01,  7.0466e-01, -2.7221e-01,  1.4419e-02, -6.4115e-01,\n",
            "           2.3902e+00, -1.4256e+00, -4.6192e-01, -1.5539e+00, -3.3382e-01,\n",
            "           2.4049e-01,  2.1065e+00,  5.5087e-01, -2.9364e-01, -1.8027e+00,\n",
            "          -6.9333e-01,  1.7409e+00,  2.6979e-01,  9.5949e-01, -1.0253e+00,\n",
            "          -5.5049e-01,  1.0264e+00, -5.6696e-01, -2.6584e-01, -1.1116e+00,\n",
            "          -1.3696e+00, -6.5336e-01, -1.6125e+00, -2.2840e-01,  1.8388e+00,\n",
            "          -9.4727e-01,  1.4192e-01,  3.6959e-01, -1.7425e-02, -9.5746e-01,\n",
            "          -8.1691e-01, -2.8655e-01,  4.3434e-01, -1.3402e-01, -2.1467e+00,\n",
            "          -1.7984e+00, -6.8222e-01, -5.1905e-01],\n",
            "         [ 9.3415e-03, -1.8110e+00, -2.4427e-01,  1.3271e-01,  1.0875e+00,\n",
            "          -1.0294e-01,  8.6037e-01,  2.0778e-01,  2.0270e-01,  5.0212e-01,\n",
            "          -4.0630e-01,  6.6642e-01,  4.7654e-01, -1.4498e+00,  1.5446e+00,\n",
            "           1.0394e+00,  2.1681e+00,  4.8844e-01,  3.3594e-01, -1.2282e+00,\n",
            "          -1.1998e-01,  4.8836e-01,  1.9431e+00,  2.1693e-01, -4.7434e-01,\n",
            "          -3.6792e-01, -2.9180e-01, -1.6531e+00,  7.6917e-01, -1.1323e+00,\n",
            "           2.9590e+00,  8.1711e-01,  7.6676e-01,  1.3258e+00,  2.1029e-01,\n",
            "           1.7876e+00, -1.2128e+00,  2.0449e-01,  1.1051e+00, -5.4540e-01,\n",
            "           1.0731e-01,  8.7270e-01, -1.2800e+00, -4.6191e-01,  1.4342e+00,\n",
            "          -1.2103e+00,  1.3834e+00,  3.2373e-02,  5.4211e-01,  8.7962e-01,\n",
            "           2.7133e-01,  1.6067e+00, -1.0004e+00,  7.3916e-01, -4.9308e-01,\n",
            "           4.0730e-01, -1.0394e+00, -3.2257e-01,  7.2264e-01,  2.6743e-01,\n",
            "          -4.6733e-01,  6.9160e-01, -1.8752e+00,  3.0077e-01, -1.4684e-01,\n",
            "           1.3672e+00,  7.0744e-01,  3.2760e-01,  1.0658e+00,  1.4130e+00,\n",
            "          -1.2445e+00,  2.2273e-01,  4.5929e-01, -3.8454e-01,  6.5538e-01,\n",
            "          -1.0454e-01, -1.1134e+00,  5.1102e-01,  3.5657e-01,  1.8591e+00,\n",
            "          -9.3004e-01,  1.1186e+00,  1.7495e+00,  2.3058e+00,  3.7342e-01,\n",
            "           3.3141e-01, -1.8711e-01,  1.7704e-01,  2.9641e+00,  2.3065e-01,\n",
            "           3.2283e-01,  2.6103e-01,  3.2192e-01,  1.7745e+00,  3.1550e-01,\n",
            "          -9.3638e-01,  5.6870e-01, -9.5882e-02,  4.6282e-03, -1.4321e+00,\n",
            "          -1.5346e-01, -1.9252e-01, -3.1150e-01, -1.8119e-01, -8.7449e-01,\n",
            "          -2.7043e-02,  5.4244e-01,  1.3656e+00, -2.8419e-02, -7.4106e-01,\n",
            "          -1.6922e-02,  1.7024e+00,  4.2060e-01,  9.3170e-01,  9.8840e-01,\n",
            "          -3.9477e-01,  6.9192e-01,  1.2310e+00, -5.1262e-01, -1.2635e+00,\n",
            "           1.1440e+00,  7.6188e-01,  6.5428e-01, -1.5402e+00, -5.1761e-01,\n",
            "          -3.1536e-02, -1.0640e+00,  9.4171e-01]],\n",
            "\n",
            "        [[ 3.3737e-01, -1.7778e-01, -3.0353e-01, -5.8801e-01,  3.4861e-01,\n",
            "           6.6034e-01, -2.1964e-01, -3.7917e-01,  7.6711e-01, -1.1925e+00,\n",
            "           6.9835e-01, -1.4097e+00,  1.7938e-01,  1.8951e+00,  4.9545e-01,\n",
            "           2.6920e-01, -7.7020e-02, -1.0205e+00, -1.6896e-01,  9.1776e-01,\n",
            "           1.5810e+00,  1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01,\n",
            "          -1.5723e+00,  9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01,\n",
            "          -6.3151e-01, -2.8400e+00, -1.3250e+00,  1.7843e-01, -2.1338e+00,\n",
            "           1.0524e+00, -3.8848e-01, -9.3435e-01, -4.9914e-01, -1.0867e+00,\n",
            "           8.8054e-01,  1.5542e+00,  6.2662e-01, -1.7549e-01,  9.8284e-02,\n",
            "          -9.3507e-02,  2.6621e-01, -5.8504e-01,  8.7684e-01,  1.6221e+00,\n",
            "          -1.4779e+00,  1.1331e+00, -1.2203e+00,  1.3139e+00,  1.0533e+00,\n",
            "           1.3881e-01,  2.2473e+00, -8.0364e-01, -2.8084e-01,  7.6968e-01,\n",
            "          -6.5956e-01, -7.9793e-01,  1.8383e-01,  2.2935e-01,  5.1463e-01,\n",
            "           9.9376e-01, -2.5873e-01, -1.0826e+00, -4.4382e-02,  1.6236e+00,\n",
            "          -2.3229e+00,  1.0878e+00,  6.7155e-01,  6.9330e-01, -9.4872e-01,\n",
            "          -7.6507e-02, -1.5264e-01,  1.1674e-01,  4.4026e-01, -1.4465e+00,\n",
            "           2.5529e-01, -5.4963e-01,  1.0042e+00,  8.2723e-01, -3.9481e-01,\n",
            "           4.8923e-01, -2.1681e-01, -1.7472e+00, -1.6025e+00, -1.0764e+00,\n",
            "           9.0315e-01, -7.2184e-01, -5.9508e-01, -7.1122e-01,  6.2296e-01,\n",
            "          -1.3729e+00, -2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01,\n",
            "          -3.1861e-02, -4.7896e-01,  7.6681e-01,  2.7468e-02,  1.9929e+00,\n",
            "           1.3708e+00, -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3745e-03,\n",
            "          -9.8955e-01,  7.0161e-01, -9.4053e-01, -4.6806e-01,  1.0322e+00,\n",
            "          -2.8300e-01,  4.9275e-01, -1.4078e-02, -2.7466e-01, -7.6409e-01,\n",
            "           1.3966e+00, -9.9491e-01, -1.5822e-03,  1.2471e+00, -7.7105e-02,\n",
            "           1.2774e+00, -1.4596e+00, -2.1595e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyngitc78hv"
      },
      "source": [
        "### モデルの定義\n",
        "* MLP（多層パーセプトロン）だが、入り口に単語埋め込み層が挿入されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9asdLYng7DOu"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc1.bias.data.zero_()\n",
        "    self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc2.bias.data.zero_()\n",
        "    self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc3.bias.data.zero_()\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.embed(text)\n",
        "    x = x.mean(0) \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foU72cB48IO9"
      },
      "source": [
        "### モデルを作る\n",
        "* モデル（のインスタンス）をGPUに移動させている点に注意。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0BHCGAZ8F18"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wylQOq8N8cqI"
      },
      "source": [
        "### 損失関数とoptimizerとschedulerを作る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw34INS78cIW"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWLfu8Z8MzW"
      },
      "source": [
        "### 訓練用の関数\n",
        "* 最初の`model.train()`に注意。こうやって、モデルを訓練モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR2R4Lqh8J7n"
      },
      "source": [
        "def train(data_iterator, model, optimizer, scheduler, criterion):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch in data_iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, cls = batch.text, batch.label\n",
        "    output = model(text)\n",
        "    loss = criterion(output, cls)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  data_len = len(data_iterator.dataset)\n",
        "  return train_loss / data_len, train_acc / data_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuX8e1W8iRh"
      },
      "source": [
        "### 評価用の関数\n",
        "* 最初の`model.eval()`に注意。こうやって、モデルを評価モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGUnsJlq8Ue3"
      },
      "source": [
        "def test(data_iterator, model, criterion):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  for batch in data_iterator:\n",
        "    text, cls = batch.text, batch.label\n",
        "    with torch.no_grad():\n",
        "      output = model(text)\n",
        "      loss = criterion(output, cls)\n",
        "      loss += loss.item()\n",
        "      acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "  data_len = len(data_iterator.dataset)\n",
        "  return loss / data_len, acc / data_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8o_jDAg8osP"
      },
      "source": [
        "## 07-03 分類器の訓練と開発セットでの評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJJFv4k-8mH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "924dfd6a-c37b-4d80-e757-3e3557bbc883"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs / 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0042(train)\t|\tAcc: 80.6%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.3%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0016(train)\t|\tAcc: 94.2%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.5%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0007(train)\t|\tAcc: 97.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.3%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0003(train)\t|\tAcc: 98.9%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 87.1%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.4%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 86.5%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.7%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 86.6%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 86.6%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 87.6%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 87.8%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.1%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.4%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.2%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.2%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.3%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.3%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.3%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.4%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.2%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.3%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 87.2%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPux8PReWTXG"
      },
      "source": [
        "## 07-04 再検討\n",
        "* 訓練データ上での分類精度が100%になってしまっている。明らかにオーバーフィッティング。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jMgtmoWkty"
      },
      "source": [
        "### ドロップアウトを使う\n",
        "* モデルのインスタンスを作るときにdropoutの確率を引数pで指定できるようにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khps3ZuBWntq"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx, p=0.0):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc1.bias.data.zero_()\n",
        "    self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc2.bias.data.zero_()\n",
        "    self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc3.bias.data.zero_()\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.dropout(self.embed(text))\n",
        "    x = x.mean(0)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVXbkt6qXxNt"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXkBDXc6X1mp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5da3b7af-a02a-4f20-bc73-68ecf680eb75"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs / 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0048(train)\t|\tAcc: 76.6%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.8%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0024(train)\t|\tAcc: 90.4%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.5%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0016(train)\t|\tAcc: 93.9%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.9%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0011(train)\t|\tAcc: 95.9%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.9%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0009(train)\t|\tAcc: 96.7%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 86.8%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0007(train)\t|\tAcc: 97.3%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 88.5%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0005(train)\t|\tAcc: 98.0%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0005(train)\t|\tAcc: 98.3%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0004(train)\t|\tAcc: 98.6%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 88.8%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0003(train)\t|\tAcc: 98.9%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.2%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.2%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.2%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.4%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.4%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.7%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.4%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.3%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.4%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.6%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.5%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.3%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.7%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 88.5%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.5%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 88.8%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu3Y-wjwb0po"
      },
      "source": [
        "### L２正則化を使う\n",
        "* optimizerのweight_decayパラメータを0より大きな値にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmxEuSFJazCJ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Zr2S7ga3J4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1838733f-234f-4cbc-c92e-e5287c04849b"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs / 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0067(train)\t|\tAcc: 62.3%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 70.0%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0052(train)\t|\tAcc: 74.9%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 80.9%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0045(train)\t|\tAcc: 79.5%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 83.6%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0041(train)\t|\tAcc: 82.6%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 85.3%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0039(train)\t|\tAcc: 83.2%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 83.4%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.5%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 86.7%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0035(train)\t|\tAcc: 85.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 86.9%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0034(train)\t|\tAcc: 86.6%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.4%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0033(train)\t|\tAcc: 86.9%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 86.9%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0032(train)\t|\tAcc: 87.2%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.4%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0030(train)\t|\tAcc: 88.2%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.8%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0029(train)\t|\tAcc: 88.6%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.9%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0029(train)\t|\tAcc: 89.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.8%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0028(train)\t|\tAcc: 89.4%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.1%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0027(train)\t|\tAcc: 90.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.3%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0026(train)\t|\tAcc: 90.5%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.3%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0025(train)\t|\tAcc: 90.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.1%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0024(train)\t|\tAcc: 91.3%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0024(train)\t|\tAcc: 91.4%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.9%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0023(train)\t|\tAcc: 92.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.6%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIHA64UTdmBj"
      },
      "source": [
        "### early stopping\n",
        "* dev setでのaccuracyが4回連続で最高値を下回ったら訓練を終えることにする。\n",
        "* early stoppingの実現については、PyTorch Lightningを使う手もある。\n",
        " * https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0zclQnVdlVZ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3E_I5sRc3FF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1ac650b-09ce-49a7-bf2f-5dd19578e620"
      },
      "source": [
        "patience = 4\n",
        "early_stop_count = 0\n",
        "best_valid_acc = 0.0\n",
        "valid_acc_threshold = 0.87\n",
        "\n",
        "N_EPOCHS = 50 # エポック数を増やしておく\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs / 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n",
        "\n",
        "  # early stopping\n",
        "  if best_valid_acc <= valid_acc:\n",
        "    best_valid_acc = valid_acc\n",
        "    early_stop_count = 0\n",
        "  else:\n",
        "    early_stop_count += 1\n",
        "    if early_stop_count == patience:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0067(train)\t|\tAcc: 61.7%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 75.3%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0051(train)\t|\tAcc: 75.6%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 82.5%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0044(train)\t|\tAcc: 80.5%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 84.1%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0040(train)\t|\tAcc: 83.1%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 83.6%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.7%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 86.4%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0036(train)\t|\tAcc: 84.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 86.0%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0036(train)\t|\tAcc: 85.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 86.4%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0033(train)\t|\tAcc: 86.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.6%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0033(train)\t|\tAcc: 86.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.1%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0031(train)\t|\tAcc: 87.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.8%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0030(train)\t|\tAcc: 88.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.6%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0029(train)\t|\tAcc: 89.0%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.0%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0028(train)\t|\tAcc: 89.3%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0027(train)\t|\tAcc: 89.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.2%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0027(train)\t|\tAcc: 90.0%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.3%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0025(train)\t|\tAcc: 90.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.4%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0025(train)\t|\tAcc: 90.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.6%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0024(train)\t|\tAcc: 91.2%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.5%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0023(train)\t|\tAcc: 91.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.5%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0023(train)\t|\tAcc: 92.0%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.8%(valid)\n",
            "Epoch: 21  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0022(train)\t|\tAcc: 92.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.9%(valid)\n",
            "Epoch: 22  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0021(train)\t|\tAcc: 92.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 87.9%(valid)\n",
            "Epoch: 23  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0021(train)\t|\tAcc: 93.2%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 89.2%(valid)\n",
            "Epoch: 24  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0020(train)\t|\tAcc: 93.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 89.1%(valid)\n",
            "Epoch: 25  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0020(train)\t|\tAcc: 93.7%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.5%(valid)\n",
            "Epoch: 26  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0020(train)\t|\tAcc: 93.4%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 89.0%(valid)\n",
            "Epoch: 27  | time in 0 minutes, 4 seconds\n",
            "\tLoss: 0.0019(train)\t|\tAcc: 94.0%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 88.8%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRvkncN09MKk"
      },
      "source": [
        "## 07-05 テストセット上で評価\n",
        "* 見つけ出したベストな設定を使って、テストセット上での最終的な評価をおこなう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39XBHTCGhlUr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_gHj4x38y8h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "54c1ca61-8217-4144-f3fc-3d427272d9d6"
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_iterator, model, criterion)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.0000(test)\t|\tAcc: 88.2%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1M_VQ1xhcWq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}