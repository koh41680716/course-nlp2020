{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_PyTorch_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Ju5Lc6g45t9qjI0R2cFUAA1wHBFm2IeB",
      "authorship_tag": "ABX9TyMgPuquvlLTLyyzTjwwoF4h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/06_PyTorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hx2zN0IvyqF"
      },
      "source": [
        "# 06 PyTorch入門 (3)\n",
        "* IMDbデータセットの感情分析をPyTorchを使っておこなう。\n",
        " * \b前にscikit-learnを使って同じ作業をおこなった。\n",
        "* 参考資料\n",
        " * PyTorch公式のチュートリアル https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        "* データは以前作ったIMDbの文書埋め込みを使う。\n",
        "* sentiment analysisのもっと高度な手法については、下記リンク先を参照。\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-hkFIH1xHUX"
      },
      "source": [
        "## 06-01 fastTextによる文書埋め込みをMLPの入力として使うための準備\n",
        "* MLP(多層パーセプトロン)の学習ぐらいは、空気を吸ったり吐いたりするぐらい自然にできるようにしておこう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jB8UO3e9-_t"
      },
      "source": [
        "### データファイルが置いてあるGoogle Driveのパスを変数PATHに設定\n",
        "* データファイルの扱い方\n",
        " * Blackboardで「自然言語処理特論」へ行く。\n",
        " * 「教材/課題/テスト」→「data」→「IMDb」と順にクリックする。\n",
        " * 見えている６つの「.npy」ファイルをダウンロードする。\n",
        " * ダウンロードした6つのファイルを、自分のGoogle Driveの適当な場所にアップロードする。\n",
        " * 次のセルで、その置き場所を指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P3MzvmdrobX"
      },
      "source": [
        "PATH = '/content/drive/My Drive/2020Courses/NLP/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgVr8oKj-DJ5"
      },
      "source": [
        "### 実験の再現性確保のための設定\n",
        "* torch.backends.cudnn.deterministicをTrueにするのは、こうしないと、GPU上での計算が毎回同じ値を与えないため。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-jw4S8rhTB"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(123)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAv8yYt8-Yn0"
      },
      "source": [
        "あらかじめランタイムをGPUに設定しておこう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETpwV-Lmw-K5",
        "outputId": "7d11cc39-9c3f-4d2c-93c8-bf7405ae71e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl9euZ-P-fiG"
      },
      "source": [
        "### 単語埋め込みデータファイルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjF1vzSosL5l"
      },
      "source": [
        "texts = dict()\n",
        "labels = dict()\n",
        "for tag in ['train', 'valid', 'test']:\n",
        "  with open(f'{PATH}{tag}.npy', 'rb') as f:\n",
        "    texts[tag] = np.load(f)\n",
        "  with open(f'{PATH}{tag}_labels.npy', 'rb') as f:\n",
        "    labels[tag] = np.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE7RXSjEsWPU",
        "outputId": "4aa71c96-95ee-4c88-f2dc-97e42381acb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for tag in ['train', 'valid', 'test']:\n",
        "  print(texts[tag].shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 300)\n",
            "(5000, 300)\n",
            "(25000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7AybiDZ-jvr"
      },
      "source": [
        "### ndarrayをPyTorchのテンソルに変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuEe746MtFtr"
      },
      "source": [
        "for tag in ['train', 'valid', 'test']:\n",
        "  texts[tag], labels[tag] = torch.tensor(texts[tag]), torch.tensor(labels[tag])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0QVlHKJ-vZn"
      },
      "source": [
        "## 06-02 学習のための準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNOz5rSW-olE"
      },
      "source": [
        "### 定数の設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Klcm5_AucfM"
      },
      "source": [
        "TRAIN_SIZE, EMBED_DIM = texts['train'].shape\n",
        "NUM_CLASS = len(torch.unique(labels['train']))\n",
        "\n",
        "DEV_SIZE = labels['valid'].shape[0]\n",
        "TEST_SIZE = labels['test'].shape[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrkpdhR3vL1_",
        "outputId": "51063ed3-a22d-48c8-f6d2-0b16e10e032a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print((f'埋め込みの次元 {EMBED_DIM}, '\n",
        "  f'クラスの数 {NUM_CLASS}, '\n",
        "  f'訓練データのサイズ {TRAIN_SIZE}, '\n",
        "  f'開発データのサイズ {DEV_SIZE}, '\n",
        "  f'テストデータのサイズ {TEST_SIZE}'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "埋め込みの次元 300, クラスの数 2, 訓練データのサイズ 20000, 開発データのサイズ 5000, テストデータのサイズ 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TBR8VZLsq_H"
      },
      "source": [
        "X_train, y_train = texts['train'], labels['train']\n",
        "X_dev, y_dev = texts['valid'], labels['valid']\n",
        "X_test, y_test = texts['test'], labels['test']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipq2udez-0ez"
      },
      "source": [
        "### データローダの作成\n",
        "* shuffleをTrueにして、毎エポック異なる順で訓練データを見ていくようにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfloEv0Osj2n"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE-wx62k9d3J"
      },
      "source": [
        "## 06-03 モデルの定義と学習の準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkRnetIrs9DX"
      },
      "source": [
        "class TextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class):\n",
        "    super(TextSentiment, self).__init__()\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc1.bias.data.zero_()\n",
        "    self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc2.bias.data.zero_()\n",
        "    self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc3.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkGnlqfvQpp"
      },
      "source": [
        "model = TextSentiment(EMBED_DIM, NUM_CLASS).to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRWTIEYy_FKj"
      },
      "source": [
        "### 損失関数とoptimizerとschedulerを作る\n",
        "* https://pytorch.org/docs/stable/optim.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB0NIxhlxka5"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0ko1VZz_Kng"
      },
      "source": [
        "### 訓練用の関数\n",
        "* 前回とほぼ同じ。\n",
        "* データのフォーマットが変わっただけ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHvS00cVvaVU"
      },
      "source": [
        "def train_func():\n",
        "\n",
        "  # Train the model\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for i, (text, cls) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    text, cls = text.to(device), cls.to(device)\n",
        "    output = model(text)\n",
        "    loss = criterion(output, cls)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "  # Adjust the learning rate\n",
        "  scheduler.step()\n",
        "\n",
        "  return train_loss / TRAIN_SIZE, train_acc / TRAIN_SIZE"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0ARJYib_M84"
      },
      "source": [
        "### 評価用の関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDFVMgRqyl4Q"
      },
      "source": [
        "def test(X, y):\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  data = DataLoader(TensorDataset(X, y), batch_size=BATCH_SIZE)\n",
        "  for text, cls in data:\n",
        "    text, cls = text.to(device), cls.to(device)\n",
        "    with torch.no_grad():\n",
        "      output = model(text)\n",
        "      loss = criterion(output, cls)\n",
        "      loss += loss.item()\n",
        "      acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "  return loss / X.shape[0], acc / X.shape[0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W9fIHDa9j0P"
      },
      "source": [
        "## 06-04 分類器の訓練と評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_rGEelGzuRO",
        "outputId": "57f8aa73-e4fc-4c66-e25a-def1adad7cb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "\n",
        "N_EPOCHS = 50\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train_func()\n",
        "  dev_loss, dev_acc = test(X_dev, y_dev)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs / 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {dev_loss:.4f}(dev)\\t|\\tAcc: {dev_acc * 100:.1f}%(dev)')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0065(train)\t|\tAcc: 62.0%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 56.8%(dev)\n",
            "Epoch: 2  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0060(train)\t|\tAcc: 67.5%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 59.7%(dev)\n",
            "Epoch: 3  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0058(train)\t|\tAcc: 69.3%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 74.7%(dev)\n",
            "Epoch: 4  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0056(train)\t|\tAcc: 71.0%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 73.5%(dev)\n",
            "Epoch: 5  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0054(train)\t|\tAcc: 72.8%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 70.5%(dev)\n",
            "Epoch: 6  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0052(train)\t|\tAcc: 73.2%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 66.5%(dev)\n",
            "Epoch: 7  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0051(train)\t|\tAcc: 75.4%(train)\n",
            "\tLoss: 0.0003(dev)\t|\tAcc: 61.6%(dev)\n",
            "Epoch: 8  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0049(train)\t|\tAcc: 76.5%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 64.9%(dev)\n",
            "Epoch: 9  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0047(train)\t|\tAcc: 77.5%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 69.8%(dev)\n",
            "Epoch: 10  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0046(train)\t|\tAcc: 78.6%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 81.7%(dev)\n",
            "Epoch: 11  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0045(train)\t|\tAcc: 79.3%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 68.5%(dev)\n",
            "Epoch: 12  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0043(train)\t|\tAcc: 80.1%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 82.7%(dev)\n",
            "Epoch: 13  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0042(train)\t|\tAcc: 81.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 81.5%(dev)\n",
            "Epoch: 14  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0041(train)\t|\tAcc: 81.4%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 83.6%(dev)\n",
            "Epoch: 15  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0040(train)\t|\tAcc: 82.1%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 82.3%(dev)\n",
            "Epoch: 16  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0040(train)\t|\tAcc: 82.1%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 82.1%(dev)\n",
            "Epoch: 17  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0040(train)\t|\tAcc: 82.7%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 83.1%(dev)\n",
            "Epoch: 18  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0039(train)\t|\tAcc: 83.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 83.2%(dev)\n",
            "Epoch: 19  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0039(train)\t|\tAcc: 83.1%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.0%(dev)\n",
            "Epoch: 20  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0039(train)\t|\tAcc: 83.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 83.4%(dev)\n",
            "Epoch: 21  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.4%(train)\n",
            "\tLoss: 0.0002(dev)\t|\tAcc: 81.8%(dev)\n",
            "Epoch: 22  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.5%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.2%(dev)\n",
            "Epoch: 23  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.6%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 83.9%(dev)\n",
            "Epoch: 24  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.6%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.0%(dev)\n",
            "Epoch: 25  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.5%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 83.9%(dev)\n",
            "Epoch: 26  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.7%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 83.7%(dev)\n",
            "Epoch: 27  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.8%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.4%(dev)\n",
            "Epoch: 28  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 83.9%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 29  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 83.9%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 30  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 83.9%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 31  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 32  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 33  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 34  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 35  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 36  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.4%(dev)\n",
            "Epoch: 37  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 38  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 39  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 40  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 41  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 42  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 43  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
            "Epoch: 44  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
            "Epoch: 45  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
            "Epoch: 46  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
            "Epoch: 47  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.3%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
            "Epoch: 48  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
            "Epoch: 49  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
            "Epoch: 50  | time in 0 minutes, 0 seconds\n",
            "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
            "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbG7hxf70Ggf",
        "outputId": "dded7e5d-c048-48b6-8492-24c79c6b48cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(X_test, y_test)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.0000(test)\t|\tAcc: 83.5%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUzVkJ2v-tt_"
      },
      "source": [
        "# 課題6\n",
        "* モデルやoptimizerやschedulerを変更して、dev setの分類性能をできるだけ向上させてみよう。\n",
        "* その後、自分で選択した設定を使って、最終的にtest setで評価しよう。"
      ]
    }
  ]
}